---
title: "The Spread of the Data"
output:
  bookdown::html_document2:
    includes:
      in_header: Variance_image.html
---

<div class="alert alert-info">
  **Module learning objectives:**
  <ol>
  <li>  </li>
  <li>  </li>
  <li>  </li>
  <li> Write function for the variance and standard deviation </li>
  <li> Explain why the sample variance would be downwardly biased if we did not correct it by diving by (N-1) </li>
  </ol>
</div>

<!-- <link href="styles.css" rel="stylesheet">  -->
<!--         <div class="image-descript"> -->
<!-- 					<img class="main-image" src="giraffe_forest.png"> -->
<!-- 					<div class="color-overlay"></div> -->
<!-- 					<div class="image-text"> -->
<!-- 						<div class="lil-image-text">Tiny Giraffes</div> -->
<!-- 						<div class="big-image-text"><strong>Big Questions</strong></div> -->
<!-- 					</div> -->
<!-- 				</div> -->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Back on the island...
After successfully calculating the mean, you return to the memory of the first day you had collected your data...There was one that was your favorite-- it was especially cute! 

-After a few days, you get acquainted with this very small one. the favorite- how rare is its smallness?

...You return back to the data and you wonder-- how do you formally assess how spread out the values of height are among these small animals?



You might start by calculating the range. This gives us a rough idea of the kinds of heights we can expect on a very basic level. But, the range seems to ignore important information (i.e. outliers).

(Include Interactive plot where you see two different data sets with same range. One has outliers influencing the range-- while the other just has a lot more variability.)

The range is not good enough to capture the real difference.

What is a more stable measurment?

The answer is by calculating the variance.
<div style="margin-top:50px"></div>
<center>![](giraffe_forest.png){width=800px}</center>
<div style="margin-bottom:50px"></div>

##Why is variance important?
You need a solid understanding of variance in order to grasp the mechanics of any statistical test.

<div style="margin-top:50px"></div>
<center>![](giraffe_ruler.png){width=800px}</center>
<div style="margin-bottom:50px"></div>

##How to calculate variance?
First, the idea is to capture how far away individual observations lie from the known mean. In other words, we could subtract the mean from each height.

Using \@ref(eq:equation2), it's easy to translate this into code in R.

```{r, include=FALSE}
tutorial::go_interactive(height = 400)
```


```{r ex="variance", type="sample-code"}

heights1 <- c(1,5,6,4,7,4,9,2)

# Subtract the mean from each height in the vector "heights1"


# Print out "heights1_diff"


```
```{r ex="variance", type="solution"}
heights1 <- c(1,5,6,4,7,4,9,2)

# Subtract the mean from each height in the vector "heights1"
heights1_diff <- heights1 - mean(heights1)

# Print out "heights1_diff"
heights1_diff
```
```{r ex="variance", type="sct"}
test_object("heights1_diff")

test_output_contains("heights1_diff", incorrect_msg= "Did you print 'heights1_diff'?")
success_msg("Great!")
```
<div style="margin-top:50px"></div>

This is a great start, but we're back to the problem of needing to summarize multiple values. Since these newly calculated values are both negative and positive, we quickly realize that adding them up (like the first step when calculating the mean) would not be a productive idea since the negatives cancel the positives.

What's the easiest thing to do when you want to retain how far away a point is from the mean irrespective of whether it's above or below the mean? How about taking the absolute value?

(Great explanation for why not to take the abs val)

Instead, we square the difference. Now, we have positive values that we can sum up. We call the number we get, the sum of squares. 

<div style="margin-bottom:50px">
</div>
\begin{equation}
 (\#eq:equation1)
 \Large {\sum_{i=1}^n (x_i - \bar{x})^2}
 \end{equation}
<div style="margin-bottom:50px">
</div>

The sum of squares is an important calculation that we will see again for other statistical operations. 

(Image of squares shown in a physical/concrete way)

We need to take into account how many observations contributed to these sum of squares. So, we divide by our n, we take the average of the squared differences from the mean. This is the variance.


<div style="margin-bottom:50px">
</div>
\begin{equation}
 (\#eq:equation2)
 \Large \sigma^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n}
 \end{equation}
<div style="margin-bottom:50px">
</div>


The problem with variance is that it is a scaleable number, and knowing the variance alone is not enough to gauge whether the spread is large or small without knowing the units of the data. So, the standard deviation fixes that. By taking the square root of the variance, we can "standardize" the sum of squares. The revised equation is below:

Note: going back to the original scale of the data.....unsquaring. 


<div style="margin-bottom:50px">
</div>
\begin{equation}
 (\#eq:equation3)
 \Large \sigma = \sqrt{\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n}}
 \end{equation}
<div style="margin-bottom:50px"></div>


Bell curve - place holder
 point out outliers in illustration
 
  * Example of how to calculate the variance with the giraffe illustrations
 
Population vs sample (N vs N-1)

  * We have to correct the calculated variance with by dividing by N-1. Let's understand why:

  * Let's recall that when we calculate the sum of squares, we only have the sample mean \bar{x} to go off of as our center point. 
  
  (Insert \bar{x} sum of squares graph)

  * We must first acknowledge that while the population mu is unknowable, the chance that the sample \bar{x} and the population mu are the same is unlikely. 
    + It's also worth pointing out that the risk that \bar{x} and mu are not even values close to each other is much increased when your sample \bar{x} has been calculated with a small sample. 
    
  * Recognizing that the true population mean value is probably some *other* value than our \bar{x} value, let's recalculate the sum of squares, this time using the true population mu as our center point, which we will represent with a line at an arbitrary distance away from the one at \bar{x} that we used previously.

 (Next frame with mu SS in diff color than xbar SS)
 
  * When we compare the SS in both of these scenarios (1: using \bar{x} or 2: using some other center line), we see that the sum of squares from the other line will *always* be greater than the \bar{x} SS. This is true because by definition of being the sample mean, the line at \bar{x} will always be the "center" of the values in our sample. It's location already minimizes the total distance of all the observations to a center. A line at any other location (i.e. the true population) would be a line that is not mimimizing the distance for observations in our sample!
  
  (Show OBVIOUS comparison of the stacked up squares from mu line being greater)

  * Therefore, when we calculate the SS (and consequently, the variance and the standard deviation) using the sample mean \bar{x}, we are most likely arriving at a value that is downwardly biased compared to what the true variance or standard deviation would be if we were able to know and use the population mean mu. 
  
  * This is why we can "adjust" our sample variance by diving by N-1 instead of just N. By diving by a smaller value (i.e. N-1 instead of N), we can ensure that the overall value of the variance and standard deviation will a little larger, correcting for the downward bias we've described. 
  
 * How badly is the variance downwardly biased? * 
  (NOTE: refer to just variance or also standard dev from here on....?)
  Well, it depends on how far away \bar{x} is from the true mu. The further away it is, the worse the downward bias will be!
  
  * I want to avoid having a very downwardly biased variance! What controls how far away \bar{x} is from mu?
  The sample size! Again, the larger the sample, the greater the likelihood that your sample mean will resemble the population mean. 
  
  
  * Having a downwardly biased variance is not a good thing-- so if we focus on situations where samples end up having downwardly biased variance, what can we learn about these samples?
  
  (Insert behemoth dot plot)
  
  * When the samples whose means \bar{x} are far off from the true population mean, tend to have downwardly biased variance. [WHAT IS A BETTER POINT TO TRANSITION TO???]
  
  * Take a look at the points that are far away from the true population  mean-- the samples represented by these points are primarily had small sample sizes (dark blue color)
  
Notes: 
- Things to think about: 
- Show how the Sum of Square for a non-normal distribution is not balanced on either side of the mean
- Maybe have scale illo showing sum of squares being unbalanced/ unequal


