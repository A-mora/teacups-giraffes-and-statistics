---
title: "Intro to Inference"
output:
  bookdown::html_document2:
    includes:
      in_header: inference1_image.html
      after_body: foot.html
---

THIS IS TEST!!!!!!!

<div class="alert alert-info">
  **Module learning objectives:**
  <ol>
  <li> Determine how to quantify the accuracy and precision of an estimate </li>
  <li> Describe the concept of statistical inference </li>
  <li> Understand the concept of sampling distributions </li>
  <li> Describe the relationship between the spread of the sampling distribution and sample size </li>
  <li> Define and calculate standard error </li>
  <li> Calculate standard error using a single sample's standard deviation </li>
  <li> Use the standard error to construct 95% confidence intervals </li>
  </ol>
</div>

# How accurate is our estimate of the mean?

Let's revisit the first few days during which we collected Island 1 heights. We were able to calculate the mean of our sample ${\bar{x}}$ and verify that the heights were normally distributed. However, we know that ${\bar{x}}$ is only an *estimate* of the true population mean, ${\mu}$, which would be the true value of interest. It is unlikely that we will ever know the value of ${\mu}$, since access to all possible observations is rare. Therefore we will have to rely on ${\bar{x}}$ estimates from random samples drawn from the population as the best approximation of ${\mu}$.

Not all sample means are created equal. Some are better estimates than others. Recall the [animation](mean.html#mean_animation) showing the relationship between sample size and variability of the mean. As we learned from this animation, large samples are necessary to get an accurate estimate of ${\mu}$.

The reason we care about our sample estimate's accuracy is because we want to be able to test hypotheses about the population by making inferences. **Statistical inference** uses math to draw conclusions about the population taking sample uncertainty into account. One common use of statistical inference is related to hypotheses. For example, say that our hypothesis is that the population value of giraffe heights on Island 1 is less than 11 cm. We can make some inferences about whether or not our hypothesis is true based on what we learn from our sample of giraffe heights. We'll revisit this question a few times. 

The mean of our sample of 50 giraffes from Island 1 was:

```{r, echo=FALSE}
set.seed(12)
heights_island1 <- rnorm(50,10,2)
``` 

```{r}
mean(heights_island1)
``` 

# Creating a sampling distribution

How can we quantify the accuracy and precision of this estimate, given its sample size? One way to illustrate this is to generate data not just from a single sample but from many samples of the same size (N) drawn from the same population. Imagine that after you complete the first collection of 50 observations from Island 1, you wake up one morning with no memory of collecting data at all---and so you go out and collect 50 giraffe heights again, and subsequently calculate the mean. Further imagine that this groundhog day (or more correctly, groundhog week) situation repeats itself many, many times.

When you finally return to your sanity, you find stacks of notebooks filled with mean values from each of your individual data collections. 

<center>![](Notebooks.jpg){width=600px}</center>

Instead of viewing this as a massive waste of time, you make the best out of the situation and create a histogram of all the means, in other words you create a plot showing the distribution of the sample means. 

The animation below illustrates the process of creating this final histogram--called the **sampling distribution**. 

On the left side, each histogram represents a sample (e.g. your first week's data collection) and correspondingly, each dot signifies an observation. After each histogram is completed, ${\bar{x}}$ is calculated. This ${\bar{x}}$ value is then subsequently added to the histogram of the sampling distibution. As you can see below, this process is repeated multiple times, allowing the sampling distribution to build up.


[ANIMATION]

Looking at the spread of ${\bar{x}}$ values that this groundhog experience generated, we can get a sense of the range of all possible estimates of ${\mu}$ that a sample of 50 giraffes can produce. 

[ STATIC PLOT] 

This is the first hint of the precision of our estimate, which we'll quantify in more detail later on, but for now it's enough to notice that the range of possible ${\bar{x}}$ values is ____ to _____. (Desiree thinks people might get confused and need some extra context....). This means that ${\bar{x}}$ values outside of this range are essentially improbable.

Let's return to our hypothesis that the true mean of giraffe heights on Island 1 is less than 11 cm. Our sampling distribution suggests that ${\mu}$ is less than 11 cm [CHOOSE A NUMBER THAT FALLS OUTSIDE OF THIS SAMPLING DISTRIBUTION RANGE] since values greater than that are not within the range of this sampling distribution. 


# Sample size and sampling distribution

Back to the idea that larger samples are "better", we can explore what happens if we repeat the groundhog scenario, this time sampling 500 individuals each time, instead of 50. For completeness, let's imagine the same marathon data collection using samples that are smaller---of 5 giraffes each. We compare the histograms from all three scenarios below.

[Three sampling distributions]

What do we notice?

1) All histograms look normal. 
2) All distributions have approximately the same mean.
3) Distributions generated from larger samples are less dispersed.

The mean of the sampling distribution is a mean of means. It can be interpreted as the mean that results from a large sample made up of all the individual observations from each of the samples whose ${\bar{x}}$ values are included in the sampling distribution. 

[Desiree illustration: something to help keep track of all the "means" and the "samples"]

Try changing the number of observations that make up each sample, and see what the resulting sampling distribution looks like as well as the standard deviation of this distribution. See if you can confirm for yourself that the above points are true.

[INSERT DATACAMP WINDOW]

# Standard Error of the Mean
As we've done before, we want to quantify this spread of mean estimates with a single value. We've already learned how to quantify a measure of spread--the standard deviation. If we take the standard deviations of each of the three different sampling scenarios above, then we accept that *distributions based on smaller samples should have larger standard deviations*. 

Using our three sampling distributions from above, calculate the standard deviation of each one. Confirm that the italicized point above is true in the window below. (If you're working in R locally, use your "homemade" standard deviation function from the [Variance](Variance.html) module.)

[DATA CAMP WINDOW]

When you calculate the standard deviation of a sampling distribution of ${\bar{x}}$ values, you are calculating the **standard error of the mean (SEM)**, or just "standard error". This is the value that we use to capture the level of precision of our sample estimate. But, we need a better and more efficient way to arrive at this value without relying on a groundhog day situation. Keep reading to learn more.

# Time for a tea break!
<center>![](Slingshot.jpg){width=700px}</center>

# Standard Error in practice
The equation used for calculating the standard error of the mean using theory (i.e. without going out and resampling MANY times) is a bit complicated, but if you're interested, you can learn more about it [here](https://stats.stackexchange.com/questions/89154/general-method-for-deriving-the-standard-error). But, we can capture the relationship of the terms in the equation with the plot below.

[INSERT PLOT SHOWING y-axis SEM and x-axis N]

Look at the plot above, hover over the points, and see if you can deduce how standard error of the mean, standard deviation, and sample size are related. Here are some hints to help you come up with the equation:

* SEM will be on one side of the equation, standard devation, and N will be on the other.
* The equation will involve division.
* There is one more missing piece of the puzzle: When you look at the shape of the plot above. What type of function does this remind you of? We haven't covered this explicitly, but take a look [here](https://www.mathsisfun.com/sets/functions-common.html) and see if you get any ideas.

Use the window below as a calculator to see if you can figure out the equation.

[DataCamp window exercise]
  
In case you weren't able to figure it out, check out this [link](https://en.wikipedia.org/wiki/Standard_error) for the equation for calculating the SEM. Remember that we're working with the sample standard deviation ($s$), so make sure you find the correct equation.

# Confirming that the SEM equation works
Let's test out this equation against what we concluded from the sampling distributions example with the N=50 case. Does the SEM seem like a good approximiation of the sampling distribution?

The object `heights_island1` contains our sample of N=50. And the object `sampling_distibution_N50` contains the data from the corresponding "groundhog" sampling distribution.

[DataCamp window exercise, set.seed for the regular Island 1 sample. set.seed for N=50 sampling distribution]


# How do we apply the SEM?
Now that we have a better understanding of how to gauge the precision of our sample estimates, we can test our hypothesis once and for all using inference.

To formally make inferences, we need to revisit the principles of the [empirical rule](Variance.html#empirical) to construct confidience intervals. (Confidence intervals are just one way to make inferences-- we'll discuss other ways later.)

It just so happens that +/- 2 SEM from a point estimate will capture ~95% of the sampling distribution (remember, that the SEM is just the standard deviation of the sampling distribution, so the empirical rule applies just the same here). Actually, we were a little bit sloppy earlier when we said 2 standard deviations captures 95% of a normal distribution; this will actually give you __% of the data. The true value is 1.96--and this is what we use to construct a 95% confidence interval (CI).

A 95% CI is the range of values that we are 95% certain contains the true mean of the population. We want to know whether our guess of 11 cm falls above of this range of certainty. If it does -- we can be sure enough that the true average of giraffe heights on Island 1 is less than 11cm.

Use the window below to find out and make your first inference!
[DataCamp WINDOW]
<center> ![](Babyinference.jpg){width=600px} </center>

# Things to think about
95% CI is not a measure of [variability](https://www.graphpad.com/guides/prism/7/statistics/stat_more_about_confidence_interval.htm?toc=0&printWindow)

[NIcer looking version of the plot]